{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd2be9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 17391 (Score: 0.8350) ---\n",
      "Effective Quotation\n",
      "Relating approaches to language-integrated query\n",
      "James Cheney\n",
      "\n",
      "Sam Lindley\n",
      "\n",
      "arXiv:1310.4780v3 [] 11 Apr 2014\n",
      "\n",
      "The University of Edinburgh\n",
      "jcheney@inf.ed.ac.uk,\n",
      "Sam.Lindley@ed.ac.uk\n",
      "\n",
      "Gabriel Radanne\n",
      "\n",
      "Philip Wadler\n",
      "\n",
      "ENS Cachan\n",
      "gabriel.radanne@zoho.com\n",
      "\n",
      "The University of Edinburgh\n",
      "wadler@inf.ed.ac.uk\n",
      "\n",
      "Abstract\n",
      "Language-integrated query techniques have been explored in a\n",
      "number of different language designs. We consider two different, type-safe approaches employed by Links and F#...\n",
      "\n",
      "--- Result 25653 (Score: 0.8049) ---\n",
      "Lienert 1\n",
      "\n",
      "Simulation of Genetic\n",
      "Algorithm: Traffic\n",
      "Light Efficiency\n",
      "Senior Research Paper\n",
      "By: Eric Lienert\n",
      "\n",
      "\fLienert 2\n",
      "\n",
      "Abstract:\n",
      "Traffic is a problem in many urban areas worldwide. Traffic flow is dictated by certain devices\n",
      "such as traffic lights. The traffic lights signal when each lane is able to pass through the\n",
      "intersection. Often, static schedules interfere with ideal traffic flow. The purpose of this project\n",
      "was to find a way to make intersections controlled with traffic lights more eff...\n",
      "\n",
      "--- Result 27159 (Score: 0.7920) ---\n",
      "MNRAS 000, 1–13 (2017)\n",
      "\n",
      "Preprint 5 October 2017\n",
      "\n",
      "Compiled using MNRAS LATEX style file v3.0\n",
      "\n",
      "Effective Image Differencing with ConvNets for Real-time\n",
      "Transient Hunting\n",
      "Nima Sedaghat1? and Ashish Mahabal2 †\n",
      "1 Department\n",
      "2 Center\n",
      "\n",
      "of Computer Science, University of Freiburg, Georges-Koehler-Allee 052, 79110 Freiburg, Germany\n",
      "for Data Driven Discovery, Caltech, 1200 E California Blvd., Pasadena, CA 91125\n",
      "\n",
      "arXiv:1710.01422v1 [astro-ph.IM] 4 Oct 2017\n",
      "\n",
      "Accepted XXX. Received YYY; in original form ZZZ\n",
      "...\n",
      "\n",
      "--- Result 21324 (Score: 0.7878) ---\n",
      "Naturalizing a Programming Language via Interactive Learning\n",
      "Sida I. Wang, Samuel Ginn, Percy Liang, Christopher D. Manning\n",
      "Computer Science Department\n",
      "Stanford University\n",
      "{sidaw, samginn, pliang, manning}@cs.stanford.edu\n",
      "\n",
      "arXiv:1704.06956v1 [cs.CL] 23 Apr 2017\n",
      "\n",
      "Abstract\n",
      "Our goal is to create a convenient natural language interface for performing wellspecified but complex actions such as analyzing data, manipulating text, and querying databases. However, existing natural language interfaces for ...\n",
      "\n",
      "--- Result 18115 (Score: 0.7839) ---\n",
      "VISUAL FEATURES FOR CONTEXT-AWARE SPEECH RECOGNITION\n",
      "Abhinav Gupta, Yajie Miao, Leonardo Neves, and Florian Metze\n",
      "\n",
      "arXiv:1712.00489v1 [cs.CL] 1 Dec 2017\n",
      "\n",
      "Language Technologies Institute, Carnegie Mellon University\n",
      "Pittsburgh, PA; U.S.A.\n",
      "abhinavgupta94@gmail.com, {ymiao|lneves|fmetze}@cs.cmu.edu\n",
      "ABSTRACT\n",
      "Automatic transcriptions of consumer generated multi-media\n",
      "content such as “Youtube” videos still exhibit high word error\n",
      "rates. Such data typically occupies a very broad domain, has\n",
      "been recorde...\n"
     ]
    }
   ],
   "source": [
    "# BERT Cosine Similarity Search Engine\n",
    "# Sentence like model\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load BERT embeddings\n",
    "bert_data = np.load(\"BERT embeddings/bert_embedding.npz\")\n",
    "bert_embeddings = normalize(bert_data[\"bert_embedding\"])\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# Function to embed a query\n",
    "def embed_query(query):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        outputs = model(**inputs)\n",
    "        return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "# Function to perform search\n",
    "def search_bert(query, top_k=5):\n",
    "    query_vec = normalize(embed_query(query))\n",
    "    sims = cosine_similarity(query_vec, bert_embeddings).flatten()\n",
    "    top_indices = sims.argsort()[::-1][:top_k]\n",
    "    return top_indices, sims[top_indices]\n",
    "\n",
    "# Load the dataset text\n",
    "dataset = load_dataset(\"ccdv/arxiv-classification\", \"no_ref\")[\"train\"][:][\"text\"]\n",
    "\n",
    "# Test search\n",
    "query = \"machine learning for vision\"\n",
    "indices, scores = search_bert(query, top_k=5)\n",
    "\n",
    "# Print results\n",
    "for i, score in zip(indices, scores):\n",
    "    print(f\"\\n--- Result {i} (Score: {score:.4f}) ---\\n{dataset[i][:500]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf16f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 602 (Score: 0.5626) ---\n",
      "Double Deep Machine Learning\n",
      "Moshe BenBassat (moshe.benbassat@plataine.com)\n",
      "\n",
      "Arison School of Business, Interdisciplinary Center (IDC), Herzliya, Israel\n",
      "\n",
      "Abstract\n",
      "Very important breakthroughs in data-centric machine learning algorithms led to impressive performance in ‘transactional’\n",
      "point applications such as detecting anger in speech, alerts from a Face Recognition system, or EKG interpretation. Nontransactional applications, e.g. medical diagnosis beyond the EKG results, require AI algorithms...\n",
      "\n",
      "--- Result 214 (Score: 0.5540) ---\n",
      "Human-in-the-loop Artificial Intelligence\n",
      "Fabio Massimo Zanzotto\n",
      "University of Rome Tor Vergata\n",
      "\n",
      "arXiv:1710.08191v1 [] 23 Oct 2017\n",
      "\n",
      "fabio.massimo.zanzotto@uniroma2.it\n",
      "\n",
      "Abstract\n",
      "Little by little, newspapers are revealing the bright future that Artiﬁcial Intelligence (AI) is building. Intelligent machines will help everywhere. However, this\n",
      "bright future has a dark side: a dramatic job market contraction before its unpredictable transformation. Hence, in a near future, large numbers of job seekers...\n",
      "\n",
      "--- Result 711 (Score: 0.5481) ---\n",
      "RoboCupSimData: A RoboCup soccer research\n",
      "dataset\n",
      "Olivia Michael1 , Oliver Obst∗1 ,\n",
      "Falk Schmidsberger2 , Frieder Stolzenburg2\n",
      "1\n",
      "\n",
      "arXiv:1711.01703v1 [] 6 Nov 2017\n",
      "\n",
      "2\n",
      "\n",
      ": Western Sydney University, Centre for Research in Mathematics\n",
      ": Harz University of Applied Sciences, Automation and Computer Sciences Department\n",
      "∗\n",
      ": Corresponding author: o.obst@westernsydney.edu.au\n",
      "Abstract\n",
      "\n",
      "RoboCup is an international scientific robot competition in which teams of multiple robots\n",
      "compete against each other. Its...\n",
      "\n",
      "--- Result 850 (Score: 0.5406) ---\n",
      "Can Machines Think in Radio Language?\n",
      "\n",
      "arXiv:1710.02648v3 [] 15 December 2017\n",
      "\n",
      "Yujian Li\n",
      "College of Computer Science, Beijing University of Technology, Beijing 100124, China\n",
      "Email: liyujian@bjut.edu.cn\n",
      "Abstract: People can think in auditory, visual and tactile forms of language, so can machines\n",
      "principally. But is it possible for them to think in radio language? According to a first principle\n",
      "presented for general intelligence, i.e. the principle of language's relativity, the answer may\n",
      "give an ...\n",
      "\n",
      "--- Result 118 (Score: 0.5302) ---\n",
      "Machine Learning Application in the Life Time of Materials\n",
      "Xiaojiao Yu\n",
      "Abstract:\n",
      "Materials design and development typically takes several decades from the initial discovery to\n",
      "commercialization with the traditional trial and error development approach. With the accumulation of\n",
      "data from both experimental and computational results, data based machine learning becomes an\n",
      "emerging field in materials discovery, design and property prediction. This manuscript reviews the\n",
      "history of materials science ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load Word2Vec model\n",
    "# Make sure the .model and .vectors.npy files are in the same folder\n",
    "wv_model = KeyedVectors.load(\"models/word2vec-google-news-300.model\")\n",
    "\n",
    "# Load Dataset\n",
    "dataset = load_dataset(\"ccdv/arxiv-classification\", \"no_ref\")[\"train\"][:1000]  # Limit for speed\n",
    "documents = dataset[\"text\"]\n",
    "\n",
    "# Function to embed a document\n",
    "def document_to_w2v(doc, model):\n",
    "    tokens = [word for word in doc.split() if word in model]\n",
    "    if not tokens:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean([model[token] for token in tokens], axis=0)\n",
    "\n",
    "# Build Document Embedding Matrix\n",
    "doc_embeddings = np.array([document_to_w2v(doc, wv_model) for doc in documents])\n",
    "doc_embeddings = normalize(doc_embeddings)\n",
    "\n",
    "# Function to embed a query\n",
    "def query_to_w2v(query, model):\n",
    "    return normalize(document_to_w2v(query, model).reshape(1, -1))\n",
    "\n",
    "# Function to search\n",
    "def search_word2vec(query, top_k=5):\n",
    "    query_vec = query_to_w2v(query, wv_model)\n",
    "    sims = cosine_similarity(query_vec, doc_embeddings).flatten()\n",
    "    top_indices = sims.argsort()[::-1][:top_k]\n",
    "    return [(i, sims[i], documents[i]) for i in top_indices]\n",
    "\n",
    "# Test search\n",
    "query = \"deep learning for robotics\"\n",
    "results = search_word2vec(query, top_k=5)\n",
    "\n",
    "# Display results\n",
    "for i, score, doc in results:\n",
    "    print(f\"\\n--- Result {i} (Score: {score:.4f}) ---\\n{doc[:500]}...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
