# Exploring-text-embeddings-and-transformer-models
For the UvA course "Machine learning for Physics and Astronomy". This project investigates methods for generating vector representations of scientific texts using TF-IDF, Word2Vec, and BERT-based embeddings. These embeddings are evaluated through classification and clustering tasks using a dataset of Arxiv papers.

In project.ipynb, you will find: (1 ) Code for loading the dataset. (2) Code for downloading the Word2Vec vectors locally. Please store the generated embeddings in the designated folders we created.